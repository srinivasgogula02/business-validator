import { ModelMessage, streamText, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';
import 'dotenv/config';
import * as readline from 'node:readline/promises';

// â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const MODEL = 'openai/gpt-4.1';
const MAX_STEPS = 3;

const SYSTEM_PROMPT = `You are a helpful assistant with access to web search.

When the user asks about:
- Current events, breaking news, or recent developments
- Real-time data (stock prices, weather, sports scores, etc.)
- Information that may have changed after your training cutoff
- Specific facts you're unsure about

â€¦use the web_search tool to find up-to-date information.

When presenting search results:
- Synthesize the information into a clear, concise answer
- Cite your sources with URLs when available
- If search results are conflicting, mention the discrepancy
- If the search doesn't return useful results, say so honestly`;

// â”€â”€ Terminal setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const terminal = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
});

const messages: ModelMessage[] = [];

// â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const EXIT_COMMANDS = new Set(['exit', 'quit', 'bye', '/exit', '/quit']);

function isExitCommand(input: string): boolean {
    return EXIT_COMMANDS.has(input.trim().toLowerCase());
}

function printBanner() {
    console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
    console.log('â•‘          ðŸŒ  Web Search Chat  (Vercel AI Gateway)      â•‘');
    console.log('â•‘  Model: openai/gpt-4.1  â€¢  Search: OpenAI WebSearch    â•‘');
    console.log('â•‘  Type "exit" to quit  â€¢  Ctrl+C to interrupt            â•‘');
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
}

// â”€â”€ Main loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function main() {
    printBanner();

    while (true) {
        const userInput = await terminal.question('You: ');

        // Handle empty input
        if (!userInput.trim()) continue;

        // Handle exit commands
        if (isExitCommand(userInput)) {
            console.log('\nðŸ‘‹  Goodbye!\n');
            terminal.close();
            process.exit(0);
        }

        messages.push({ role: 'user', content: userInput });

        try {
            const result = streamText({
                model: MODEL,
                system: SYSTEM_PROMPT,
                messages,
                tools: {
                    web_search: openai.tools.webSearch({}),
                },
                stopWhen: stepCountIs(MAX_STEPS),
            });

            let fullResponse = '';
            let isFirstTextChunk = true;
            let searchCount = 0;

            for await (const part of result.fullStream) {
                switch (part.type) {
                    case 'text-delta':
                        if (isFirstTextChunk) {
                            process.stdout.write('\nAssistant: ');
                            isFirstTextChunk = false;
                        }
                        fullResponse += part.text;
                        process.stdout.write(part.text);
                        break;

                    case 'tool-call':
                        searchCount++;
                        console.log(`\nðŸ”  Searching the web (query ${searchCount})...`);
                        break;

                    case 'tool-result':
                        console.log('âœ…  Search results received â€” generating answer...');
                        break;

                    case 'source':
                        // Display source URLs from search results
                        if ('url' in part && part.url) {
                            const title = ('title' in part && part.title) ? part.title : part.url;
                            console.log(`   ðŸ“Ž ${title}: ${part.url}`);
                        }
                        break;

                    case 'error':
                        console.error('\nâš ï¸  Stream error:', part.error);
                        break;
                }
            }

            process.stdout.write('\n\n');

            // Store the final text in conversation history
            if (fullResponse) {
                messages.push({ role: 'assistant', content: fullResponse });
            }
        } catch (error: unknown) {
            const errMsg =
                error instanceof Error ? error.message : String(error);
            console.error(`\nâŒ  Error: ${errMsg}`);
            console.log('   (You can keep chatting â€” the error was for this turn only)\n');

            // Remove the failed user message so history stays clean
            messages.pop();
        }
    }
}

// â”€â”€ Graceful shutdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
process.on('SIGINT', () => {
    console.log('\n\nðŸ‘‹  Interrupted â€” goodbye!\n');
    terminal.close();
    process.exit(0);
});

// â”€â”€ Start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
main().catch((err) => {
    console.error('Fatal error:', err);
    process.exit(1);
});
